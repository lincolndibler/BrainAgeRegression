# -*- coding: utf-8 -*-
"""save_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10LYkHxjRe29VCei6m0jQaCtKjQY96gh8

# 1.) Imports
"""

import os
import torch
import pickle

class BrainAgeSave:
    def __init__(self, save_dir):
        """
        Initialize with a directory to save/load model and evaluation data.
        """
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)

    def save_model_weights(self, model, filename="model_weights.pth"):
        path = os.path.join(self.save_dir, filename)
        torch.save(model.state_dict(), path)
        print(f"âœ… Model weights saved to: {path}")

    def save_full_model(self, model, filename="full_model.pt"):
        path = os.path.join(self.save_dir, filename)
        torch.save(model, path)
        print(f"âœ… Full model saved to: {path}")

    def save_eval_data(self, data_dict, filename="eval_data.pkl"):
        path = os.path.join(self.save_dir, filename)
        with open(path, "wb") as f:
            pickle.dump(data_dict, f)
        print(f"âœ… Evaluation data saved to: {path}")

    def load_eval_data(self, filename="eval_data.pkl"):
        path = os.path.join(self.save_dir, filename)
        with open(path, "rb") as f:
            data = pickle.load(f)
        print(f"ðŸ“‚ Loaded evaluation data from: {path}")
        return data

    def load_model_weights(self, model, filename="model_weights.pth", device="cpu"):
        path = os.path.join(self.save_dir, filename)
        model.load_state_dict(torch.load(path, map_location=device))
        print(f"ðŸ“¥ Model weights loaded from: {path}")
        return model

    def load_full_model(self, filename="full_model.pt", device="cpu"):
        path = os.path.join(self.save_dir, filename)
        model = torch.load(path, map_location=device)
        print(f"ðŸ“¥ Full model loaded from: {path}")
        return model